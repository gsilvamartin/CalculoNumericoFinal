"use strict";
var __assign = (this && this.__assign) || function () {
    __assign = Object.assign || function(t) {
        for (var s, i = 1, n = arguments.length; i < n; i++) {
            s = arguments[i];
            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))
                t[p] = s[p];
        }
        return t;
    };
    return __assign.apply(this, arguments);
};
Object.defineProperty(exports, "__esModule", { value: true });
var FloatVector_1 = require("../../../types/vector/FloatVector");
var GradientDescent_1 = require("../GradientDescent");
var LinearKernel_1 = require("../kernels/LinearKernel");
/**
 * A {@link Regressor} model which uses an ordinary least squares model with regularization to
 * predict a continuous target.
 * The optimal set of parameters is computed with gradient descent.
 * @public
 */
var LinearRegressor = /** @class */ (function () {
    function LinearRegressor(hyperParameters) {
        this._hyperParameters = Object.freeze(hyperParameters);
        this._theta = undefined;
    }
    /**
     * Get the coefficients of the trained linear regression model, or
     * `undefined` if the model has not been trained.
     * @public
     */
    LinearRegressor.prototype.getParameters = function () {
        return this._theta;
    };
    /**
     * {@inheritDoc Regressor.getHyperParameters}
     */
    LinearRegressor.prototype.getHyperParameters = function () {
        return __assign(__assign({}, this.getDefaultHyperParameters()), this._hyperParameters);
    };
    /**
     * {@inheritDoc Regressor.train}
     */
    LinearRegressor.prototype.train = function (data, target) {
        var _this = this;
        var initialTheta = FloatVector_1.FloatVector.builder().random(data.getNumberOfColumns() + 1, -0.01, 0.01);
        this._theta = GradientDescent_1.gradientDescent(this._hyperParameters)(initialTheta, function (theta) { return ({
            cost: _this.calculateCost(data, target, theta),
            gradient: _this.calculateGradient(data, target, theta)
        }); });
    };
    /**
     * {@inheritDoc Regressor.predict}
     */
    LinearRegressor.prototype.predict = function (data) {
        if (!this._theta)
            throw new Error("Cannot call predict before train");
        return this.makePredictions(data, this._theta);
    };
    LinearRegressor.prototype.calculateCost = function (data, target, theta) {
        var lambda = this.getHyperParameters().lambda;
        var predictions = this.makePredictions(data, theta);
        var residuals = target.scalarMultiply(-1).add(predictions);
        var squaredResiduals = residuals.map(function (entry) { return Math.pow(entry, 2); });
        var meanSquaredError = squaredResiduals.toArray().reduce(function (prev, curr) { return prev + curr; }, 0) / data.getNumberOfRows();
        var penalty = function (x) { return x * x; };
        var paramSum = theta.toArray().reduce(function (prev, curr) { return penalty(prev) + curr; }, 0);
        var regularizationTerm = (paramSum - theta.getEntry(0)) * lambda;
        return meanSquaredError + regularizationTerm;
    };
    LinearRegressor.prototype.calculateGradient = function (data, target, theta) {
        var lambda = this.getHyperParameters().lambda;
        var m = data.getNumberOfRows();
        var predictions = this.makePredictions(data, theta);
        var residuals = target.scalarMultiply(-1).add(predictions);
        var gradientTerm = LinearKernel_1.LinearKernel(data)
            .transpose()
            .apply(residuals)
            .scalarMultiply(1 / m);
        var regularizationTerm = theta.scalarMultiply(lambda / m).set(0, 0);
        return gradientTerm.add(regularizationTerm);
    };
    LinearRegressor.prototype.makePredictions = function (data, theta) {
        return LinearKernel_1.LinearKernel(data).apply(theta);
    };
    LinearRegressor.prototype.getDefaultHyperParameters = function () {
        return {
            lambda: 0,
            alpha: 0.01
        };
    };
    return LinearRegressor;
}());
exports.LinearRegressor = LinearRegressor;
//# sourceMappingURL=LinearRegressor.js.map